{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11896308,"sourceType":"datasetVersion","datasetId":7477896}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:45:21.767656Z","iopub.execute_input":"2025-05-25T10:45:21.768025Z","iopub.status.idle":"2025-05-25T10:45:21.785786Z","shell.execute_reply.started":"2025-05-25T10:45:21.768001Z","shell.execute_reply":"2025-05-25T10:45:21.784486Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/sbki-mkb/Dataset (1).csv\n","output_type":"stream"}],"execution_count":92},{"cell_type":"markdown","source":"# LEVEL 1\n\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndf = pd.read_csv(\"/kaggle/input/sbki-mkb/Dataset (1).csv\")\n\nnumeric_df = df.select_dtypes(include=[np.number])\n\ncorr_matrix = numeric_df.corr()\n\nplt.figure(figsize=(14, 10))\nsns.heatmap(corr_matrix, \n            annot=True, \n            fmt=\".2f\", \n            cmap=\"coolwarm\", \n            linewidths=0.5, \n            square=True, \n            cbar_kws={\"shrink\": .75})\n\nplt.title(\"Correlation Heatmap of Numeric Features\", fontsize=16)\nplt.xticks(rotation=45, ha='right')\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:45:21.787832Z","execution_failed":"2025-05-25T10:46:02.933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[['Feature_1', 'Feature_2', 'Feature_3']].hist(bins=15, figsize=(12, 6), layout=(1, 3))\nplt.suptitle(\"Histograms of Anonymized Features\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\nfor i, feature in enumerate(['Feature_1', 'Feature_2', 'Feature_3']):\n    sns.scatterplot(x=df[feature], y=df['G3'], ax=axes[i])\n    axes[i].set_title(f'{feature} vs G3')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nfor i, feature in enumerate(['Feature_1', 'Feature_2', 'Feature_3']):\n    plt.subplot(1, 3, i+1)\n    sns.boxplot(data=df, x='sex', y=feature)\n    plt.title(f\"{feature} by Sex\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.934Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LEVEL 2","metadata":{}},{"cell_type":"code","source":"\nmissing_info = df.isnull().sum()\nmissing_info = missing_info[missing_info > 0].sort_values(ascending=False)\n\nprint(\"Missing Values in Each Column:\")\nprint(missing_info)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['higher'] = df['higher'].fillna(df['higher'].mode()[0])\ndf['famsize'] = df['famsize'].fillna(df['famsize'].mode()[0])\n\ndf['Fedu'] = df['Fedu'].fillna(df['Fedu'].median())\ndf['traveltime'] = df['traveltime'].fillna(df['traveltime'].median())\ndf['freetime'] = df['freetime'].fillna(df['freetime'].median())\n\nfor col in ['absences', 'Feature_1', 'Feature_2', 'Feature_3', 'G2']:\n    df[col] = df[col].fillna(df[col].median())\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(df.isnull().sum().sort_values(ascending=False).head(10))\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.934Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LEVEL 3","metadata":{}},{"cell_type":"markdown","source":"**Do female and male students differ in their final grades?**","metadata":{}},{"cell_type":"code","source":"\nplt.figure(figsize=(8, 5))\nsns.violinplot(data=df, x='sex', y='G3', inner='box', palette='Set2')\nplt.title('Distribution of Final Grades (G3) by Gender')\nplt.xlabel('Gender')\nplt.ylabel('Final Grade (G3)')\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.934Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**How does mother's education level(medu) impact student performance?**","metadata":{}},{"cell_type":"code","source":"sns.set(style=\"whitegrid\")\nplt.figure(figsize=(8, 6))\nsns.barplot(data=df, x='Medu', y='G3', palette='Blues_d', errorbar=None)\nplt.title(\"Average Final Grade (G3) by Mother's Education Level\", fontsize=14)\nplt.xlabel(\"Mother's Education Level (0 = none to 4 = higher ed)\", fontsize=12)\nplt.ylabel(\"Average Final Grade (G3)\", fontsize=12)\nplt.tight_layout()\nplt.show()\nplt.figure(figsize=(8, 6))\nsns.barplot(data=df, x='Fedu', y='G3', palette='Greens_d', errorbar=None)\nplt.title(\"Average Final Grade (G3) by Father's Education Level\", fontsize=14)\nplt.xlabel(\"Father's Education Level (0 = none to 4 = higher ed)\", fontsize=12)\nplt.ylabel(\"Average Final Grade (G3)\", fontsize=12)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.934Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Does alcohol consumption (Dalc) impact academic performance?**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nsns.barplot(data=df, x='Dalc', y='G3', ci=None, palette='viridis')\nplt.title('Average Final Grade (G3) by Daily Alcohol Consumption')\nplt.xlabel('Daily Alcohol Consumption (Dalc)')\nplt.ylabel('Average Final Grade (G3)')\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.935Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\njitter_strength = 0.15\nx_jitter = df['freetime'] + np.random.uniform(-jitter_strength, jitter_strength, size=len(df))\ny_jitter = df['goout'] + np.random.uniform(-jitter_strength, jitter_strength, size=len(df))\n\nplt.figure(figsize=(8,6))\nplt.scatter(x_jitter, y_jitter, alpha=0.6, edgecolors='w', s=80)\nplt.title('Scatterplot of Free Time vs Going Out with Friends (with Jitter)')\nplt.xlabel('Free Time (after school)')\nplt.ylabel('Going Out with Friends (frequency)')\nplt.xticks([1,2,3,4,5])\nplt.yticks([1,2,3,4,5])\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.935Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Does access to the internet at home affect absences?**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nsns.boxplot(data=df, x='internet', y='absences', palette='pastel')\nplt.title('Absences by Internet Access at Home')\nplt.xlabel('Internet Access at Home')\nplt.ylabel('Number of Absences')\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.935Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LEVEL 4","metadata":{}},{"cell_type":"markdown","source":"**ENSEMBLE VOTING**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd\ndf['romantic'] = LabelEncoder().fit_transform(df['romantic'])\nX = df.drop(columns=['romantic'])\ny = df['romantic']\nX = pd.get_dummies(X, drop_first=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nlog_clf = LogisticRegression(max_iter=1000)\nrf_clf = RandomForestClassifier(random_state=42)\nxgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\nensemble_clf = VotingClassifier(\n    estimators=[('lr', log_clf), ('rf', rf_clf), ('xgb', xgb_clf)],\n    voting='soft'\n)\nensemble_clf.fit(X_train, y_train)\ny_pred = ensemble_clf.predict(X_test)\nprint(\"Ensemble Model Performance:\\n\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.935Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**XGBoost**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd\ndf['romantic'] = LabelEncoder().fit_transform(df['romantic'])  # Yes → 1, No → 0\nX = df.drop(columns=['romantic'])\ny = df['romantic']\nX = pd.get_dummies(X, drop_first=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nxgb_model = XGBClassifier(\n    use_label_encoder=False,\n    eval_metric='logloss',\n    random_state=42,\n    n_estimators=100,\n    learning_rate=0.1,\n    max_depth=3\n)\n\nxgb_model.fit(X_train, y_train)\ny_pred = xgb_model.predict(X_test)\nprint(\"XGBoost Performance:\\n\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.935Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**CATBOOST**","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nX = df.drop(columns=['romantic'])\ny = df['romantic']\ncat_features = [i for i, col in enumerate(X.columns) if X[col].dtype == 'object']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = CatBoostClassifier(\n    iterations=300,\n    learning_rate=0.1,\n    depth=6,\n    eval_metric='F1',\n    random_seed=42,\n    verbose=50\n)\n\nmodel.fit(X_train, y_train, cat_features=cat_features)\ny_pred = model.predict(X_test)\n\nprint(\"CatBoost Performance:\\n\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.935Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LEVEL 5","metadata":{}},{"cell_type":"code","source":"pip uninstall -y scikit-learn shap\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.935Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install scikit-learn==1.2.2 shap==0.42.1\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.935Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport sklearn\nimport shap\nimport sys\nimport numpy as np\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib\n\n\nprint(\"Pandas version:\", pd.__version__)\nprint(\"Seaborn version:\", sns.__version__)\nprint(\"Matplotlib version:\", matplotlib.__version__)\n\n\nprint(\"Python version:\", sys.version)\nprint(\"NumPy version:\", np.__version__)\n\n\nprint(\"sklearn version:\",sklearn.__version__)\nprint(\"shap version:\",shap.__version__)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.935Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfeatures = ['goout', 'Dalc']\nX_two = df[features]\ny_two = df['romantic'].astype(int)\n\nX_train_2D, X_test_2D, y_train_2D, y_test_2D = train_test_split(X_two, y_two, test_size=0.2, random_state=42)\nfrom catboost import CatBoostClassifier\nmodel_2D = CatBoostClassifier(iterations=300, learning_rate=0.01, depth=4, verbose=0)\nmodel_2D.fit(X_train_2D, y_train_2D)\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_decision_boundary_catboost(model, X, y, features):\n    h = 0.1\n    x_min, x_max = X[features[0]].min() - 1, X[features[0]].max() + 1\n    y_min, y_max = X[features[1]].min() - 1, X[features[1]].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n    \n    grid = pd.DataFrame({features[0]: xx.ravel(), features[1]: yy.ravel()})\n    Z = model.predict(grid)\n    Z = Z.reshape(xx.shape)\n\n    plt.contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.RdYlBu)\n    plt.scatter(X[features[0]], X[features[1]], c=y, cmap=plt.cm.RdYlBu, edgecolors='k')\n    plt.xlabel(features[0])\n    plt.ylabel(features[1])\n    plt.title(\"CatBoost Decision Boundary\")\n    plt.show()\n\nplot_decision_boundary_catboost(model_2D, X_test_2D, y_test_2D, features)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.935Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shap\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X_test)\nshap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.935Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shap\nX_test_copy = X_test.copy()\nX_test_copy['pred'] = model.predict(X_test)\nyes_index = X_test_copy[X_test_copy['pred'] == 1].index[0]\nno_index = X_test_copy[X_test_copy['pred'] == 0].index[0]\nyes_pos = X_test.index.get_loc(yes_index)\nno_pos = X_test.index.get_loc(no_index)\nstudent_yes = X_test.iloc[yes_pos]\nstudent_no = X_test.iloc[no_pos]\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X_test)\n\nshap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[yes_pos], student_yes)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.935Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shap\nX_test_copy = X_test.copy()\nX_test_copy['pred'] = model.predict(X_test)\nyes_index = X_test_copy[X_test_copy['pred'] == 1].index[0]\nno_index = X_test_copy[X_test_copy['pred'] == 0].index[0]\nyes_pos = X_test.index.get_loc(yes_index)\nno_pos = X_test.index.get_loc(no_index)\nstudent_yes = X_test.iloc[yes_pos]\nstudent_no = X_test.iloc[no_pos]\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X_test)\n\nshap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[no_pos], student_no)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:46:02.935Z"}},"outputs":[],"execution_count":null}]}